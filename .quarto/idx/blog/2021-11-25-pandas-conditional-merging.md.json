{"title":"Python Pandas - Merging With Wildcards and Conditions","markdown":{"yaml":{"title":"Python Pandas - Merging With Wildcards and Conditions","date":"2021-11-25","tags":["python"],"categories":["modeling"],"summary":"Merging two dataframes with pandas but only if certain conditions are true.","aliases":["/pandas-conditional-merging"],"canonicalUrl":"https://www.nelsontang.com/blog/2021-11-25-pandas-conditional-merging"},"headingText":"The Challenge","containsRefs":false,"markdown":"\n\n_Updated 28 Jan 2022 to use a newer pandas crossjoin method with `.merge(how='cross')`, which works on pandas > 1.2_\n\nWhat happens when you want to merge (join) two dataframes together, but only if certain conditions are true? This is easy to do when you are simply looking for matching key-value pairs in two tables, but I had a real life scenario where I had complex combinations of joins to consider.\n\n\nHere's a simplified version of the issue I was facing:\n\n1. The date in the left table was between two dates (a start and end date) in the second table\n2. ...AND the values in two other columns matched each other, OR the column on the right table was equal to 'ANY' (aka a 'wildcard' value)\n\nFor a concrete example, let's say you're working for an apparel retailer, and you offer limited-time promotions where the customer can apply for a rebate if they buy a certain brand of jacket during the promotion period. The wrinkle: you also offer a global discount across ANY brand of jacket bought in a separate promotion.\n\nYou have a table of sales volume and you're trying to map that data with a table of promotions that you're offering:\n\n### `sales_volume_table`\n\n| date       | quantity | brand    |\n| ---------- | -------- | -------- |\n| 2021-11-15 | 1        | Outdoor  |\n| 2021-11-20 | 2        | Leisure  |\n| 2021-11-25 | 3        | Athletic |\n| 2021-11-26 | 2        | Outdoor  |\n\n### `promos_table`\n\n| start_date | end_date   | brand   | rebate_per_unit |\n| ---------- | ---------- | ------- | --------------- |\n| 2021-11-01 | 2021-11-25 | ANY     | 3               |\n| 2021-11-25 | 2021-11-26 | Outdoor | 5               |\n| 2021-12-29 | 2021-12-30 | Leisure | 10              |\n\nYou can't do a simple left join because of the 'ANY' option on the right table. One way of dealing with this is modifying the data in `promos_table` so that it covers all possible `brand` categories (i.e. Outdoor, Leisure, Athletic) but for the sake of argument let's imagine that's not feasible in the real-world example.\n\n## Merge Everything You Think You'll Need and Sort it Out Later\n\nThe simplest thing I found is to merge everything you think you'll need and then filter it out later. I tried dictionaries and set logic, but couldn't find anything faster than doing the big join.\n\nSpecifically, you can do a _Cartesian Product_ (aka a Cross Join), and [here's a great example from StackOverflow](https://stackoverflow.com/questions/47472207/how-to-merge-with-wildcard-pandas) when faced with having to merge two pandas dataframes with a wildcard value. I'll walk through each step below using the StackOverflow example and our sample scenario:\n\n```python\nimport pandas as pd\n\n# Create our two dataframes\nsales_volume_table = pd.DataFrame.from_dict([\n    {'date':'2021-11-15', 'quantity':1, 'brand':'Outdoor'},\n    {'date':'2021-11-20', 'quantity':2, 'brand':'Leisure'},\n    {'date':'2021-11-25', 'quantity':3, 'brand':'Athletic'},\n    {'date':'2021-11-26', 'quantity':2, 'brand':'Outdoor'},\n])\n\npromos_table = pd.DataFrame.from_dict([\n    {'start_date':'2021-11-01', 'end_date':'2021-11-25',\n    'brand':'ANY', 'rebate_per_unit':3},\n    {'start_date':'2021-11-25', 'end_date':'2021-11-26',\n    'brand':'Outdoor', 'rebate_per_unit':5},\n])\n\n# Create a column to join on and save the results with a Cartesian Product\nresults = sales_volume_table.merge(promos_table, how='cross')\n```\n\nThe Cartesian Product matches every row in the right dataframe with every row in the left dataframe. Here's the output below:\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\nAnd then once the results are joined together in this way, you can then apply all of your conditions using pandas indexing. I like using the `query` method since it's a little easier to read.\n\n```python\n# Filter the results where the two columns match, OR the right column is 'ANY'\nresults = results.query(\"brand_x == brand_y | brand_y=='ANY'\")\n```\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\nBut we're not done yet - we still need to filter out the dates that are relevant, so we edit our above query to incorporate additional conditions, and do a little cleanup:\n\n```python\n# Instead of one long string, we can break up the query into multiple parts\ncondition1 = \"(brand_x == brand_y | brand_y=='ANY')\"\ncondition2 = \"(start_date <= date <= end_date)\"\nqry = condition1 + \" & \" + condition2\nresults = results.query(qry)\n```\n\nWhich gives us our result (skipping the part where you drop some columns for clarity)\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\n## Performance\n\nSince we had $4$ rows in the left dataframe and $2$ in the right, the result of the Cartesian Product is $4 \\times 2$ or $8$ rows long. Something to keep in mind if your datasets get large. So if you had 5K rows of sales data and 1K rows of promotions, you'd end up with 5M rows of data after this join.\n\nBut you don't need to do a full Cartesian Product here, the key idea is to get the superset of all the data that would be relevant and then filter it down. In my real-world case I had 55k rows and 15k rows of promotions, and I had about 12 different conditions to check (a mix of date and wildcards). I started with nested for-loops, dictionaries, and set logic and it took about 30s on my 2018 MBP, but with some smarter filtering and joining with this method I was able to get the same operation done in < 10 seconds.\n\n## SQL Is Faster\n\nBut instead of doing this in Pandas, it turns out this is trivial to do in SQL. A Cartesian Product of two tables in SQL is simply:\n\n```sql\nSELECT *\nFROM sales_volume, promos\n```\n\nAnd it's even simpler to do your filtering with a `WHERE` clause, making the entire statement:\n\n```sql\nSELECT *\nFROM sales_volume, promos\nWHERE (sales_volume.brand=promos.brand or promos.brand='ANY')\nAND (start_date <= date AND date <= end_date)\n```\n\nOn my computer the pandas merging and filtering took about 4.7 ms while the sql query took 700 µs in SQLite, so a little under 7x improvement in performance.\n\n## Key Takeaway\n\nThe bottom line to take away from this is to solve a problem when you want to conditionally join two dataframes and handle things like wildcards, the easiest thing to do is to big join and filter it down from there. Or use SQL instead of Pandas.\n\n### Final Python/Pandas Result:\n\n```python\nimport pandas as pd\n\n# Create our DataFrames\nsales_volume_table = pd.DataFrame.from_dict([\n    {'date':'2021-11-15', 'quantity':1, 'brand':'Outdoor'},\n    {'date':'2021-11-20', 'quantity':2, 'brand':'Leisure'},\n    {'date':'2021-11-25', 'quantity':3, 'brand':'Athletic'},\n    {'date':'2021-11-26', 'quantity':2, 'brand':'Outdoor'},\n])\n\npromos_table = pd.DataFrame.from_dict([\n    {'start_date':'2021-11-01', 'end_date':'2021-11-25',\n     'brand':'ANY', 'rebate_per_unit':3},\n    {'start_date':'2021-11-25', 'end_date':'2021-11-26',\n     'brand':'Outdoor', 'rebate_per_unit':5},\n])\n\n# Merge it all. Notice you don't need to set a join key!\nresults = sales_volume_table.merge(promos_table, how='cross')\n# And Filter it Down\ncondition1 = \"(brand_x == brand_y | brand_y=='ANY')\"\ncondition2 = \"(start_date <= date <= end_date)\"\nqry = condition1 + \" & \" + condition2\nresults = results.query(qry)\n```\n\n### Same Thing, but Faster with SQL and SQLite\n\n```python\nimport sqlite3\n\n# Create a SQL connection to a local SQLite database\ncon = sqlite3.connect(\"sales.db\")\n\n# Add dataframes as tables in this database\nsales_volume_table.to_sql(\"sales_volume\", con, index=False, if_exists='replace')\npromos_table.to_sql(\"promos\", con, index=False, if_exists='replace')\n\n# Results in a 5x speedup from pandas!\nsql = \"\"\"SELECT *\nFROM sales_volume, promos\nWHERE (sales_volume.brand=promos.brand or promos.brand='ANY')\nAND (start_date <= date AND date <= end_date)\"\"\"\n\nresults = pd.read_sql_query(sql, con)\nresults\n```\n\n### Bonus: Even Faster with SQL and DuckDB\n\nRather than use SQLite, you could instead use [DuckDB](https://duckdb.org/), which is a fast in-memory database technology that lets you [query dataframes](https://duckdb.org/docs/guides/python/sql_on_pandas), CSV files, and Parquet files as super-high performance SQL. Here's a snippet:\n\n```python\nimport duckdb\n\n# connect to an in-memory database\ncon = duckdb.connect()\n\nsql = \"\"\"SELECT *\nFROM sales_volume_table, promos_table\nWHERE (sales_volume_table.brand=promos_table.brand or promos_table.brand='ANY')\nAND (start_date <= date AND date <= end_date)\"\"\"\n\n# query the Pandas DataFrames \"sales_volume_table\" and \"promos_table\"\nresults = con.execute(sql).df()\nresults\n```\n","srcMarkdownNoYaml":"\n\n_Updated 28 Jan 2022 to use a newer pandas crossjoin method with `.merge(how='cross')`, which works on pandas > 1.2_\n\nWhat happens when you want to merge (join) two dataframes together, but only if certain conditions are true? This is easy to do when you are simply looking for matching key-value pairs in two tables, but I had a real life scenario where I had complex combinations of joins to consider.\n\n## The Challenge\n\nHere's a simplified version of the issue I was facing:\n\n1. The date in the left table was between two dates (a start and end date) in the second table\n2. ...AND the values in two other columns matched each other, OR the column on the right table was equal to 'ANY' (aka a 'wildcard' value)\n\nFor a concrete example, let's say you're working for an apparel retailer, and you offer limited-time promotions where the customer can apply for a rebate if they buy a certain brand of jacket during the promotion period. The wrinkle: you also offer a global discount across ANY brand of jacket bought in a separate promotion.\n\nYou have a table of sales volume and you're trying to map that data with a table of promotions that you're offering:\n\n### `sales_volume_table`\n\n| date       | quantity | brand    |\n| ---------- | -------- | -------- |\n| 2021-11-15 | 1        | Outdoor  |\n| 2021-11-20 | 2        | Leisure  |\n| 2021-11-25 | 3        | Athletic |\n| 2021-11-26 | 2        | Outdoor  |\n\n### `promos_table`\n\n| start_date | end_date   | brand   | rebate_per_unit |\n| ---------- | ---------- | ------- | --------------- |\n| 2021-11-01 | 2021-11-25 | ANY     | 3               |\n| 2021-11-25 | 2021-11-26 | Outdoor | 5               |\n| 2021-12-29 | 2021-12-30 | Leisure | 10              |\n\nYou can't do a simple left join because of the 'ANY' option on the right table. One way of dealing with this is modifying the data in `promos_table` so that it covers all possible `brand` categories (i.e. Outdoor, Leisure, Athletic) but for the sake of argument let's imagine that's not feasible in the real-world example.\n\n## Merge Everything You Think You'll Need and Sort it Out Later\n\nThe simplest thing I found is to merge everything you think you'll need and then filter it out later. I tried dictionaries and set logic, but couldn't find anything faster than doing the big join.\n\nSpecifically, you can do a _Cartesian Product_ (aka a Cross Join), and [here's a great example from StackOverflow](https://stackoverflow.com/questions/47472207/how-to-merge-with-wildcard-pandas) when faced with having to merge two pandas dataframes with a wildcard value. I'll walk through each step below using the StackOverflow example and our sample scenario:\n\n```python\nimport pandas as pd\n\n# Create our two dataframes\nsales_volume_table = pd.DataFrame.from_dict([\n    {'date':'2021-11-15', 'quantity':1, 'brand':'Outdoor'},\n    {'date':'2021-11-20', 'quantity':2, 'brand':'Leisure'},\n    {'date':'2021-11-25', 'quantity':3, 'brand':'Athletic'},\n    {'date':'2021-11-26', 'quantity':2, 'brand':'Outdoor'},\n])\n\npromos_table = pd.DataFrame.from_dict([\n    {'start_date':'2021-11-01', 'end_date':'2021-11-25',\n    'brand':'ANY', 'rebate_per_unit':3},\n    {'start_date':'2021-11-25', 'end_date':'2021-11-26',\n    'brand':'Outdoor', 'rebate_per_unit':5},\n])\n\n# Create a column to join on and save the results with a Cartesian Product\nresults = sales_volume_table.merge(promos_table, how='cross')\n```\n\nThe Cartesian Product matches every row in the right dataframe with every row in the left dataframe. Here's the output below:\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\nAnd then once the results are joined together in this way, you can then apply all of your conditions using pandas indexing. I like using the `query` method since it's a little easier to read.\n\n```python\n# Filter the results where the two columns match, OR the right column is 'ANY'\nresults = results.query(\"brand_x == brand_y | brand_y=='ANY'\")\n```\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\nBut we're not done yet - we still need to filter out the dates that are relevant, so we edit our above query to incorporate additional conditions, and do a little cleanup:\n\n```python\n# Instead of one long string, we can break up the query into multiple parts\ncondition1 = \"(brand_x == brand_y | brand_y=='ANY')\"\ncondition2 = \"(start_date <= date <= end_date)\"\nqry = condition1 + \" & \" + condition2\nresults = results.query(qry)\n```\n\nWhich gives us our result (skipping the part where you drop some columns for clarity)\n\n| date       | quantity | brand_x  | start_date | end_date   | brand_y | rebate_per_unit |\n| :--------- | -------: | :------- | :--------- | :--------- | :------ | --------------: |\n| 2021-11-15 |        1 | Outdoor  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-20 |        2 | Leisure  | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-25 |        3 | Athletic | 2021-11-01 | 2021-11-25 | ANY     |               3 |\n| 2021-11-26 |        2 | Outdoor  | 2021-11-25 | 2021-11-26 | Outdoor |               5 |\n\n## Performance\n\nSince we had $4$ rows in the left dataframe and $2$ in the right, the result of the Cartesian Product is $4 \\times 2$ or $8$ rows long. Something to keep in mind if your datasets get large. So if you had 5K rows of sales data and 1K rows of promotions, you'd end up with 5M rows of data after this join.\n\nBut you don't need to do a full Cartesian Product here, the key idea is to get the superset of all the data that would be relevant and then filter it down. In my real-world case I had 55k rows and 15k rows of promotions, and I had about 12 different conditions to check (a mix of date and wildcards). I started with nested for-loops, dictionaries, and set logic and it took about 30s on my 2018 MBP, but with some smarter filtering and joining with this method I was able to get the same operation done in < 10 seconds.\n\n## SQL Is Faster\n\nBut instead of doing this in Pandas, it turns out this is trivial to do in SQL. A Cartesian Product of two tables in SQL is simply:\n\n```sql\nSELECT *\nFROM sales_volume, promos\n```\n\nAnd it's even simpler to do your filtering with a `WHERE` clause, making the entire statement:\n\n```sql\nSELECT *\nFROM sales_volume, promos\nWHERE (sales_volume.brand=promos.brand or promos.brand='ANY')\nAND (start_date <= date AND date <= end_date)\n```\n\nOn my computer the pandas merging and filtering took about 4.7 ms while the sql query took 700 µs in SQLite, so a little under 7x improvement in performance.\n\n## Key Takeaway\n\nThe bottom line to take away from this is to solve a problem when you want to conditionally join two dataframes and handle things like wildcards, the easiest thing to do is to big join and filter it down from there. Or use SQL instead of Pandas.\n\n### Final Python/Pandas Result:\n\n```python\nimport pandas as pd\n\n# Create our DataFrames\nsales_volume_table = pd.DataFrame.from_dict([\n    {'date':'2021-11-15', 'quantity':1, 'brand':'Outdoor'},\n    {'date':'2021-11-20', 'quantity':2, 'brand':'Leisure'},\n    {'date':'2021-11-25', 'quantity':3, 'brand':'Athletic'},\n    {'date':'2021-11-26', 'quantity':2, 'brand':'Outdoor'},\n])\n\npromos_table = pd.DataFrame.from_dict([\n    {'start_date':'2021-11-01', 'end_date':'2021-11-25',\n     'brand':'ANY', 'rebate_per_unit':3},\n    {'start_date':'2021-11-25', 'end_date':'2021-11-26',\n     'brand':'Outdoor', 'rebate_per_unit':5},\n])\n\n# Merge it all. Notice you don't need to set a join key!\nresults = sales_volume_table.merge(promos_table, how='cross')\n# And Filter it Down\ncondition1 = \"(brand_x == brand_y | brand_y=='ANY')\"\ncondition2 = \"(start_date <= date <= end_date)\"\nqry = condition1 + \" & \" + condition2\nresults = results.query(qry)\n```\n\n### Same Thing, but Faster with SQL and SQLite\n\n```python\nimport sqlite3\n\n# Create a SQL connection to a local SQLite database\ncon = sqlite3.connect(\"sales.db\")\n\n# Add dataframes as tables in this database\nsales_volume_table.to_sql(\"sales_volume\", con, index=False, if_exists='replace')\npromos_table.to_sql(\"promos\", con, index=False, if_exists='replace')\n\n# Results in a 5x speedup from pandas!\nsql = \"\"\"SELECT *\nFROM sales_volume, promos\nWHERE (sales_volume.brand=promos.brand or promos.brand='ANY')\nAND (start_date <= date AND date <= end_date)\"\"\"\n\nresults = pd.read_sql_query(sql, con)\nresults\n```\n\n### Bonus: Even Faster with SQL and DuckDB\n\nRather than use SQLite, you could instead use [DuckDB](https://duckdb.org/), which is a fast in-memory database technology that lets you [query dataframes](https://duckdb.org/docs/guides/python/sql_on_pandas), CSV files, and Parquet files as super-high performance SQL. Here's a snippet:\n\n```python\nimport duckdb\n\n# connect to an in-memory database\ncon = duckdb.connect()\n\nsql = \"\"\"SELECT *\nFROM sales_volume_table, promos_table\nWHERE (sales_volume_table.brand=promos_table.brand or promos_table.brand='ANY')\nAND (start_date <= date AND date <= end_date)\"\"\"\n\n# query the Pandas DataFrames \"sales_volume_table\" and \"promos_table\"\nresults = con.execute(sql).df()\nresults\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2021-11-25-pandas-conditional-merging.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.52","theme":{"light":"cosmo"},"title-block-banner":true,"title":"Python Pandas - Merging With Wildcards and Conditions","date":"2021-11-25","tags":["python"],"categories":["modeling"],"summary":"Merging two dataframes with pandas but only if certain conditions are true.","aliases":["/pandas-conditional-merging"],"canonicalUrl":"https://www.nelsontang.com/blog/2021-11-25-pandas-conditional-merging"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}